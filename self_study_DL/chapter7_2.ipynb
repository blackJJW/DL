{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chapter7_2",
      "provenance": [],
      "authorship_tag": "ABX9TyPLvWqfHgIUMPXPPlh18Kfv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackJJW/DL/blob/main/self_study_DL/chapter7_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Book : '혼자 공부하는 머신러닝 + 딥러닝', 박해선 지음, 한빛미디어"
      ],
      "metadata": {
        "id": "I3jmV9NQL2ej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 07-2 심층 신경망"
      ],
      "metadata": {
        "id": "6dGFJj7gVMmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2개의 층"
      ],
      "metadata": {
        "id": "kwMKDLcdVS9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPqP_-U6VU6N",
        "outputId": "8a49ffd2-6fe1-4677-f0dc-3c99e54e20e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이미지의 픽셀값을 0 ~ 255 범위에서 0 ~ 1 사이로 변환하고, 28 X 28 크기의 2차원 배열을 784 크기의 1차원 배열로 펼침."
      ],
      "metadata": {
        "id": "IVR-mWLEWDz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "WQxBlOt9WYir"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 은닉층(hidden layer) : 입력층과 출력층 사이에 있는 모든 층\n",
        "- 활성화 함수 : 신경망 층의 선형 방정식의 계산 값에 적용하는 함수.\n",
        "  - 출력층에 적용하는 활성화 함수는 종류가 제한되어 있음.\n",
        "  - 이진 분류일 경우 시그모이드 함수\n",
        "  - 다중 분류일 경우 소프트맥스 함수\n",
        "- 은닉층의 활성화 함수는 비교적 자유로움.\n",
        "  - 시그모이드 함수, 렐루(ReLU) 함수 등"
      ],
      "metadata": {
        "id": "MIJxcNU6WXc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784, ))\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "dWxtUcPQYJPH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 심층 신경망 만들기\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "85BxHDLlYf8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- dense1과 dense2 객체를 Sequential 클래스에 추가하여 심층 신경망(deep neural network, DNN) 생성"
      ],
      "metadata": {
        "id": "L3CS6yLFYj-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([dense1, dense2])"
      ],
      "metadata": {
        "id": "-i8ya0HvYy9a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD5ZIXE1ZKST",
        "outputId": "16f95da3-7583-4acd-ee92-1bcdaf6f1731"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 맨 첫 줄에 모델의 이름이 출력. 그 다음 이 모델에 들어 있는 층이 순서대로 나열.\n",
        "  - 이 순서는 맨 처음 추가한 은닉층에서 출력층의 순서로 나열\n",
        "- 층마다 층 이름, 클래스, 출력 크기, 모델 파라미터 개수가 출력.\n",
        "  - 층을 만들 때 name 매개변수로 이름을 지정가능.\n",
        "  - 층 이름을 지정하지 않으면 케라스가 자동으로 'dense'라고 이름을 붙임.\n",
        "- 출력을 보면 (None, 100)\n",
        "  - 첫 번째 차원은 샘플의 개수\n",
        "    - 샘플 개수가 지정되지 않았기 때문에 None\n",
        "    - 케사스 모델에서 fit()을 수행할 때 미니배치 경사 하강법 사용\n",
        "      - 샘플 개수를 고정하지 않고 어떤 배치 크기에도 유연하게 대응할 수 있도록 None으로 지정\n",
        "    - 신경망 층에 입력되거나 출력되는 배열의 첫 번째 차원을 배치 차원이라 부름.\n",
        "  - 두 번째 차원\n",
        "    - 은닉층의 뉴런 개수를 100로 지정, 100개의 출력 생성.\n",
        "      - 샘플마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축됨.\n",
        "- 마지막으로 모델 파라미터 개수가 출력.\n"
      ],
      "metadata": {
        "id": "izlFL6XKYx_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 층을 추가하는 방법"
      ],
      "metadata": {
        "id": "g8t4DG3qbXJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Sequential 클래스의 생성자 안에서 바로 Dense 클래스의 객체를 만드는 경우가 많음."
      ],
      "metadata": {
        "id": "727K1fIHbZym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(100, activation='sigmoid', input_shape=(784,), name='hidden'),\n",
        "                          keras.layers.Dense(10, activation='softmax', name='output')\n",
        "                          ], name = '패션 MNIST 모델')"
      ],
      "metadata": {
        "id": "olHWLdrtbnyW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0GvRFnJcbT1",
        "outputId": "5e1103c7-94de-4779-f79a-f0d46e870e8e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- add() 메서드를 이용한 층 추가"
      ],
      "metadata": {
        "id": "Xi4OP_G4caSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784, )))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "pRXpiOxMd1Ue"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2JQcLmBeMLs",
        "outputId": "f5b10911-229e-4ad5-98d4-d150bba80b66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPSmj1MHeQbB",
        "outputId": "70717f9c-f9a9-4c17-a534-ab7e77189c79"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 8s 3ms/step - loss: 0.5638 - accuracy: 0.8071\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4084 - accuracy: 0.8539\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3742 - accuracy: 0.8638\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3516 - accuracy: 0.8729\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3331 - accuracy: 0.8783\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa78fde4490>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 렐루 함수"
      ],
      "metadata": {
        "id": "cz5MkSsreK-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 렐루(ReLU) 함수\n",
        "  - 아주 간단.\n",
        "  - 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고 음수일 경우에는 0으로 만듦.\n",
        "  - $max(0, z)$ : z가 0보다 크면 z를 출력하고 z가 0보다 작으면 0을 출력\n",
        "  - 이미지 처리에서 좋은 성능\n"
      ],
      "metadata": {
        "id": "IkCpdudhesaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Flatten 클래스\n",
        "  - 배치 차원을 제외하고 나머지 입력 차원을 모두 일렬로 펼치는 역할.\n",
        "  - 입력에 곱해지는 가중치나 절편이 없음.\n",
        "    - 인공 신경망의 성능을 위해 기여하는 바는 없음.\n",
        "  - Flatten 클래스를 층처럼 입력층과 은닉층 사이에 추가하기 때문에 이를 층이라 부름.\n",
        "  - Flatten 층은 입력층 다음에 추가."
      ],
      "metadata": {
        "id": "AgpXd9yufchX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "zOSsb4nYgGc9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYb9vfFAgwt8",
        "outputId": "5aecf4b8-dcf4-459d-dc81-ebf9b44f1465"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 첫 번째 등장하는 Flatten 클래스에 포함된 모델 파라미터는 0개.\n",
        "- 케라스의 Flatten 층을 신경망 모델에 추가하면 입력값의 차원을 짐작 가능.\n"
      ],
      "metadata": {
        "id": "d5BaDxKPg3n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "o2qgAuG3igDd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIbw53kHjBh1",
        "outputId": "ee55ecf5-128a-405d-c864-0d0b0e4a0323"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5293 - accuracy: 0.8148\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3936 - accuracy: 0.8585\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3569 - accuracy: 0.8721\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3342 - accuracy: 0.8789\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3184 - accuracy: 0.8857\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa78fc0c3d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y55IfmojbIt",
        "outputId": "d2bc23d5-c63d-49d0-af85-41b0682b9ec7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3602 - accuracy: 0.8755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3602057695388794, 0.8755000233650208]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 옵티마이저"
      ],
      "metadata": {
        "id": "fkTkgqpcjAxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 은닉층, 활성화 함수, 층의 종류, batch_size, epochs 등 -> 하이퍼 파라미터 "
      ],
      "metadata": {
        "id": "cUFW21CRj3Um"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- compile() 메서드에서는 케라스의 기본 경사 하강법 알고리즘인 RMSprop을 사용.\n",
        "  - 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공.\n",
        "    - 옵티마이저(optimizer)\n",
        "    "
      ],
      "metadata": {
        "id": "Ad_HfFG2k622"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 가장 기본적인 optimizer -> 확률적 경사 하강법(SGD)"
      ],
      "metadata": {
        "id": "xPoMhTTAlcaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "0aKiTydQlpEW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 위 코드와 동일\n",
        "\n",
        "sgd = keras.optimizers.SGD()\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')"
      ],
      "metadata": {
        "id": "oJK_R-m9l51p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 만약 SGD 클래스이 학습률 기본값이 0.01일 때 이를 바꾸고 싶다면 learning_rate를 지정."
      ],
      "metadata": {
        "id": "cjzXT2ocmhk3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(learning_rate=0.1)"
      ],
      "metadata": {
        "id": "-d5eKdIQpaR3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기본 경사 하강법 옵티마이저\n",
        "\n",
        "SGD(learing_rate=0.01) -> 모멘텀(momentum > 0) -> 네스테로프 모멘텀(nesterov = True)\n",
        "\n",
        "- 적응적 학습률 옵티마이저\n",
        "\n",
        "RMSprop -> Adam\n",
        "\n",
        "Adagrad"
      ],
      "metadata": {
        "id": "O7cmOM-Mpmfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SGD 클래스의 momentum 매개변수의 기본값은 0\n",
        "  - 이를 0보다 큰 값으로 지정하면 마치 이전의 그레이디언트를 가속도처럼 사용하는 모멘텀 최적화(momentum optimization)를 사용.\n",
        "    - 보통 momentum은 0.9이상을 지정\n",
        "- SGD 클랫의 nesterov 매개변수를 False에서 True로 바꾸면 네스테로프 모멘텀 최적화(nesterov momentum optimizer 또는 네스테로프 가속 경사)를 사용"
      ],
      "metadata": {
        "id": "iEUSyisCqSfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "zENFNhv7rHvy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 네스테로프 모멘텀은 모멘텀 최적화를 2번 반복하여 구현.\n",
        "- 대부분의 경우 네스테로프 모멘텀 최적화가 기본 확률적 경사 하강법보다 더 나은 성능을 제공."
      ],
      "metadata": {
        "id": "yBRJcIstrThU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델이 최적점에 가까이 갈수록 학습률을 낮출 수 있음.\n",
        "  - 이렇게 하면 안정적으로 최적점에 수렴할 가능성이 높음.\n",
        "  - 이런 학습률을 적응적 학습률(adaptive learning rate)라고 함\n",
        "  - 학습률 매개변수를 튜닝하는 수고를 덜 수 있는 것이 장점\n",
        "- 대표적인 옵티마이저는 Adagrad, PMSprop"
      ],
      "metadata": {
        "id": "wIyqrhOxrjnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer = adagrad, loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "-jPWR3HWsJnz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer = rmsprop, loss = 'sparse_categorical_crossentropy', metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "WVGwzZzqseHL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모멘텀 최적화와 RMSprop의 장점을 접목한 것이 Adam"
      ],
      "metadata": {
        "id": "flVtwNoxsrZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "JhoyR9oLs397"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5pgakKjtSBF",
        "outputId": "17c1de54-1f98-426c-c37b-e4c9dc34457f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5216 - accuracy: 0.8180\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3914 - accuracy: 0.8591\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3508 - accuracy: 0.8718\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3246 - accuracy: 0.8817\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3048 - accuracy: 0.8883\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa78fa64d50>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gagGZJImtphg",
        "outputId": "ea507453-1767-4b88-88c2-25db4551dd4b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 4ms/step - loss: 0.3498 - accuracy: 0.8761\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34981411695480347, 0.8760833144187927]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 마무리"
      ],
      "metadata": {
        "id": "zWt2qnMVt3HQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 키워드로 끝내는 핵심 포인트"
      ],
      "metadata": {
        "id": "wo6CwDy-t5F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 심층 신경망 : 2개 이상의 층을 포함한 신경망. 종종 다층 인공 신경망, 심층 신경망, 딥러닝을 같은 의미로 사옹\n",
        "- 렐루 함수 : 이미지 분류 모델의 은닉층에 만힝 사요하는 활성화 함수.\n",
        "  - 시그모이드 함수는 층이 많을 수로 활성화 함수의 양쪽 끝에서 변화가 작기 때문에 학습이 어려워짐.\n",
        "  - 렐루 함수는 이런 문제가없으며 계산도 간단.\n",
        "- 옵티마이저 : 신경망의가중치와 절편을 학습하기 위한 알고리즘 또는 방법을 말함.\n",
        "  - 케라스에는 다양한 경사 하강버빙 구현\n",
        "    - 대표적으로 SGD, 네스테로프 모멘텀, RMSprop, Adam 등이 있음"
      ],
      "metadata": {
        "id": "CY9Kh3eJt87r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 핵심 패키지와 함수"
      ],
      "metadata": {
        "id": "SiDpvsPYuzP2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> TensorFlow\n",
        "- add() : 케라스 모델에 층을 추가.\n",
        "  - 케라스 모델의 add() 메서드는 keras.layers 패키지 아래에 있는 객체를 입력받아 신경망 모델을 추가.\n",
        "  - add() 메서드를 호출하여 전달한 순서대로 층이 차례대로 늘어남.\n",
        "- summary() : 케라스 모델의 정보를 출력하는 메서드.\n",
        "  - 모델에 추가된 층의 종류와 순서, 모델 파라미터 개수를 출력.\n",
        "  - 층을 만들 때 name 매개변수로 이름을 지정하먄 summary() 메서드 출력에서 구분하기 쉬움.\n",
        "- SGD : 기본 경사 하강법 옵티마이저 클래스.\n",
        "  - learning_rate : 학습률 지정, 기본값 = 0.01\n",
        "  - momentum : 0 이상의 값을 지정하겸 모멘텀 최적화를 수행.\n",
        "  - nesterov : True로 설정하면, 네트테로브 모멘텀 최적화를 수행.\n",
        "- Adagrad : Adagrad 옵티마이저 클래스\n",
        "  - learnig_rate : 학습률을 지정하며 기본값 = 0.001\n",
        "  - Adagrad : 그레이디언트 제곱을 누적하여 학습률을 나눔.\n",
        "    - initial_accumulator_value 매개변수에서 누적 초깃값을 지정할 수 있으며 기본값 = 0.1\n",
        "- RMSprop : RMSprop 옵티마이저 클래스.\n",
        "  - learnig_rate : 학습률 지정, 기본값 = 0.001\n",
        "  - Adagrad 처럼 그레이디언트 제곱으로 학습률을 나누지만 최근의 그레이디언트를 사용하기 위해 지수 감소를 사옹.\n",
        "    - rho : 감소 비율 지정, 기본값 = 0.9\n",
        "- Adam : Adam 옵티마이저 클래스\n",
        "  - learning_rate : 학습률 지정, 기본값 = 0.001\n",
        "  - 모멘텀 최적화에 있는 그레이디언트의 지수 감소 평균을 조절하기 위해 beta_1 매개변수가 있으며, 기본값 = 0.9\n",
        "  - RMSprop에 있는 그레이디언트의 지수 감소 평균을 조절하기 위해 beta_2 매개변수가 있으며, 기본값 = 0.999"
      ],
      "metadata": {
        "id": "FHm63RPYu1f2"
      }
    }
  ]
}