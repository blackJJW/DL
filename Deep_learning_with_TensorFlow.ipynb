{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMht0YwFwmeW3Pmb/sAH/Gh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackJJW/DL/blob/main/Deep_learning_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XOR Experiment"
      ],
      "metadata": {
        "id": "GrKphlCp2yd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "63j6JmHnC1ee"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])"
      ],
      "metadata": {
        "id": "BbA-28BkC7jb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJpEyjzCDuXF",
        "outputId": "ad9f6f5b-49d3-4628-ee88-a944535ecd17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 2), (4,))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier, LogisticRegression"
      ],
      "metadata": {
        "id": "tUzm0zwWEIuQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Least squares"
      ],
      "metadata": {
        "id": "AQavCa2dD2i-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_LS = RidgeClassifier()\n",
        "model_LS.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpLemkmbEFmm",
        "outputId": "6b01d818-458a-4e19-f535-9b44cdbfa2e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RidgeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LS.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFYVovFnFbR3",
        "outputId": "c7a6a4c1-7731-4aa1-ad05-12cf47116b35"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LS.score(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNtp6hkwFejN",
        "outputId": "b5e4c6c3-c827-47d8-e1e9-015ad6c15c09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "AdysaKRFFhrQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR = LogisticRegression()\n",
        "model_LR.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjQYMFSfFmWg",
        "outputId": "3cdc14b9-0299-4d64-f586-5c9a2d70be0b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v33Ea8oFsCS",
        "outputId": "b7044824-0e65-4b12-e315-82e2b9547063"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR.score(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9Q9l46EFuwd",
        "outputId": "268fa0a4-0dc1-40dc-f726-6c9425761385"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K2J-UnnJFxqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DNN"
      ],
      "metadata": {
        "id": "RUP6wwY3F7rM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras"
      ],
      "metadata": {
        "id": "vgBR_jN0F-wB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUqzk3vrGEDA",
        "outputId": "33751080-6bf9-4297-ec10-e75a91d4f82f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'keras.api._v2.keras.models' from '/usr/local/lib/python3.7/dist-packages/keras/api/_v2/keras/models/__init__.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "lTJOWBkUGHvL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 - layer DNN"
      ],
      "metadata": {
        "id": "mVQdGC5VGXl2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN = Sequential() # DNN 모델의 기본적인 틀\n",
        "model_DNN.add(Dense(10, activation='relu')) # hidden layer 추가\n",
        "model_DNN.add(Dense(1, activation='sigmoid')) # output layer 추가"
      ],
      "metadata": {
        "id": "VFtJshy3Gk7n"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiler\n",
        "model_DNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "# 추가적인 설정\n",
        "# optimizer : 어떤 종류의 gradient descent algorithm을 사용할지\n",
        "# loss : 어떤 loss function 을 사용할지\n",
        "# binary classification의 경우 'binary_crossentropy' 사용\n",
        "# metrics : train 과정에서 추적하고 싶은 값"
      ],
      "metadata": {
        "id": "c_fyKeoKITf8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN.fit(X, y, epochs=1000, verbose=0)\n",
        "# verbose : train 과정 출력\n",
        "# 0 : 출력x, 1 : 출력o"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgQHXLPgJT89",
        "outputId": "db3a5eae-adbf-4674-ab76-9b93f73fe98a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0d875adf10>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN.evaluate(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKJjrhOsJrrS",
        "outputId": "60b79d71-87a2-4b4d-85f4-b8bac0446942"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 122ms/step - loss: 0.1564 - acc: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.15642674267292023, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qQ3Dv-CBKLyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Experiment"
      ],
      "metadata": {
        "id": "8SA2ydGoK1xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "ZtKYnOhVK55X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amkmQ19HK83Y",
        "outputId": "5657d306-0c04-46de-d7db-4837e425d806"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxGpgMB2LMLl",
        "outputId": "fc22c21e-09ac-4a17-a3c1-6fe375144e62"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi5nVd0VLPX_",
        "outputId": "76a6d1b7-e360-4079-8a5f-8a852379e9d3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T34vFvh6LnPB",
        "outputId": "9deda6cc-b6aa-4fd4-f5e3-ecbe99ceef6f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pre-processing : 0 ~ 1사이의 값으로 변환\n",
        "X_train, X_test = X_train/255.0, X_test/255.0"
      ],
      "metadata": {
        "id": "N3C-NitaLvkd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB3_2nMkMGNS",
        "outputId": "a36970b3-a607-447c-a538-0089a1da01f4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "j6f0HPptMICx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "\n",
        "plt.imshow(X_train[0], cmap='Greys') # image 출력, cmap : image 색상 명시\n",
        "plt.colorbar() # 옆에 각 값이 나타내는 색깔을 표현\n",
        "plt.title(y_train[10], fontsize=20) # 제목으로 label 값 표시\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "iqM2C6ZtMe9-",
        "outputId": "34b8dfff-cb8a-404f-9264-2dc1d338f2e0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hp_5thSHNGtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training with 2-layer DNN"
      ],
      "metadata": {
        "id": "h-GVRIB3OP78"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "6CiZ1t4JOToI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN_MNIST = Sequential()\n",
        "model_DNN_MNIST.add(Flatten(input_shape=(28, 28))) # 1-dim으로 변환하는 layer\n",
        "model_DNN_MNIST.add(Dense(64, activation='relu')) # hidden layer\n",
        "model_DNN_MNIST.add(Dense(10, activation='softmax')) # output layer"
      ],
      "metadata": {
        "id": "XMg3d41LTPct"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN_MNIST.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "metadata": {
        "id": "z4j6ufXYUWu_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "model_DNN_MNIST.fit(X_train, y_train, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osSD9FigU1Fs",
        "outputId": "75293c5c-b3f3-4fb0-a822-4c221a9a67c8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6734 - acc: 0.8286\n",
            "Epoch 2/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3458 - acc: 0.9031\n",
            "Epoch 3/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2968 - acc: 0.9165\n",
            "Epoch 4/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2657 - acc: 0.9249\n",
            "Epoch 5/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2422 - acc: 0.9317\n",
            "Epoch 6/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2231 - acc: 0.9373\n",
            "Epoch 7/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2073 - acc: 0.9420\n",
            "Epoch 8/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1944 - acc: 0.9457\n",
            "Epoch 9/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1829 - acc: 0.9483\n",
            "Epoch 10/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1730 - acc: 0.9518\n",
            "Epoch 11/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1646 - acc: 0.9541\n",
            "Epoch 12/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1571 - acc: 0.9563\n",
            "Epoch 13/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1500 - acc: 0.9579\n",
            "Epoch 14/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1439 - acc: 0.9600\n",
            "Epoch 15/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1383 - acc: 0.9617\n",
            "Epoch 16/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1334 - acc: 0.9630\n",
            "Epoch 17/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1286 - acc: 0.9646\n",
            "Epoch 18/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1243 - acc: 0.9658\n",
            "Epoch 19/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1201 - acc: 0.9669\n",
            "Epoch 20/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1163 - acc: 0.9683\n",
            "Epoch 21/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1126 - acc: 0.9693\n",
            "Epoch 22/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1094 - acc: 0.9695\n",
            "Epoch 23/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1063 - acc: 0.9710\n",
            "Epoch 24/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1033 - acc: 0.9715\n",
            "Epoch 25/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1006 - acc: 0.9724\n",
            "Epoch 26/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0980 - acc: 0.9732\n",
            "Epoch 27/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0956 - acc: 0.9735\n",
            "Epoch 28/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0929 - acc: 0.9742\n",
            "Epoch 29/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0908 - acc: 0.9747\n",
            "Epoch 30/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0886 - acc: 0.9756\n",
            "Epoch 31/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0866 - acc: 0.9760\n",
            "Epoch 32/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0846 - acc: 0.9770\n",
            "Epoch 33/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0828 - acc: 0.9770\n",
            "Epoch 34/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0811 - acc: 0.9774\n",
            "Epoch 35/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0792 - acc: 0.9783\n",
            "Epoch 36/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0777 - acc: 0.9787\n",
            "Epoch 37/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0758 - acc: 0.9790\n",
            "Epoch 38/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0745 - acc: 0.9800\n",
            "Epoch 39/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0730 - acc: 0.9801\n",
            "Epoch 40/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0715 - acc: 0.9803\n",
            "Epoch 41/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0700 - acc: 0.9811\n",
            "Epoch 42/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0689 - acc: 0.9812\n",
            "Epoch 43/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0676 - acc: 0.9815\n",
            "Epoch 44/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0664 - acc: 0.9821\n",
            "Epoch 45/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0651 - acc: 0.9827\n",
            "Epoch 46/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0641 - acc: 0.9826\n",
            "Epoch 47/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0629 - acc: 0.9831\n",
            "Epoch 48/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0619 - acc: 0.9834\n",
            "Epoch 49/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0607 - acc: 0.9837\n",
            "Epoch 50/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0599 - acc: 0.9843\n",
            "Epoch 51/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0588 - acc: 0.9843\n",
            "Epoch 52/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0579 - acc: 0.9845\n",
            "Epoch 53/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0569 - acc: 0.9847\n",
            "Epoch 54/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0559 - acc: 0.9851\n",
            "Epoch 55/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0550 - acc: 0.9854\n",
            "Epoch 56/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0542 - acc: 0.9858\n",
            "Epoch 57/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0534 - acc: 0.9860\n",
            "Epoch 58/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0526 - acc: 0.9861\n",
            "Epoch 59/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0517 - acc: 0.9861\n",
            "Epoch 60/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0511 - acc: 0.9867\n",
            "Epoch 61/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0504 - acc: 0.9870\n",
            "Epoch 62/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0495 - acc: 0.9867\n",
            "Epoch 63/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0487 - acc: 0.9871\n",
            "Epoch 64/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0481 - acc: 0.9877\n",
            "Epoch 65/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0473 - acc: 0.9877\n",
            "Epoch 66/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0467 - acc: 0.9879\n",
            "Epoch 67/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0460 - acc: 0.9882\n",
            "Epoch 68/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0455 - acc: 0.9882\n",
            "Epoch 69/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0448 - acc: 0.9886\n",
            "Epoch 70/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0442 - acc: 0.9886\n",
            "Epoch 71/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0435 - acc: 0.9888\n",
            "Epoch 72/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0430 - acc: 0.9890\n",
            "Epoch 73/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0423 - acc: 0.9891\n",
            "Epoch 74/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0418 - acc: 0.9896\n",
            "Epoch 75/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0413 - acc: 0.9897\n",
            "Epoch 76/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0406 - acc: 0.9898\n",
            "Epoch 77/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0401 - acc: 0.9902\n",
            "Epoch 78/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0396 - acc: 0.9903\n",
            "Epoch 79/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0392 - acc: 0.9901\n",
            "Epoch 80/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0386 - acc: 0.9904\n",
            "Epoch 81/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0381 - acc: 0.9906\n",
            "Epoch 82/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0375 - acc: 0.9908\n",
            "Epoch 83/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0371 - acc: 0.9909\n",
            "Epoch 84/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0367 - acc: 0.9908\n",
            "Epoch 85/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0362 - acc: 0.9913\n",
            "Epoch 86/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0359 - acc: 0.9915\n",
            "Epoch 87/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0353 - acc: 0.9915\n",
            "Epoch 88/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0350 - acc: 0.9915\n",
            "Epoch 89/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0345 - acc: 0.9914\n",
            "Epoch 90/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0340 - acc: 0.9919\n",
            "Epoch 91/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0336 - acc: 0.9921\n",
            "Epoch 92/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0331 - acc: 0.9921\n",
            "Epoch 93/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0329 - acc: 0.9920\n",
            "Epoch 94/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0325 - acc: 0.9922\n",
            "Epoch 95/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0321 - acc: 0.9926\n",
            "Epoch 96/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0316 - acc: 0.9925\n",
            "Epoch 97/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0313 - acc: 0.9927\n",
            "Epoch 98/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0309 - acc: 0.9929\n",
            "Epoch 99/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0305 - acc: 0.9931\n",
            "Epoch 100/100\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0302 - acc: 0.9933\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ca9090790>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN_MNIST.predict(X_test[0]).argmax(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezhb0V7_VbyY",
        "outputId": "1a2d4f94-75a5-4fa7-823c-0660ed6ea5d1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_DNN_MNIST.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "xkYYiZe2XOXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b96ebd3-1182-446d-ec12-bfc286aa144b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0785 - acc: 0.9760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07852160930633545, 0.9760000109672546]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training MNIST with Logistics Regression"
      ],
      "metadata": {
        "id": "-IbtE4doYjf-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "id": "6FK5OD5zYvnL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc66328-6e71-4d3a-826e-8dfb32bc3cf9"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_LR = X_train.reshape((60000, -1))\n",
        "X_test_LR = X_test.reshape((10000, -1))"
      ],
      "metadata": {
        "id": "aU_r_V74Y1Qz"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_LR.shape, X_test_LR.shape"
      ],
      "metadata": {
        "id": "nh72_z5yZes_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f15dad7-9646-4874-8212-201dfd8dda50"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR_MNIST = LogisticRegression()"
      ],
      "metadata": {
        "id": "jyp0VDXSsm98"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR_MNIST.fit(X_train_LR, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNMDpxBAthMh",
        "outputId": "c1f05d78-3172-4311-d171-5bb3e01cdc3d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR_MNIST.predict(X_test_LR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HLXVdVLtmwp",
        "outputId": "75cf8314-1c40-4d29-a620-4e03df78d528"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_LR_MNIST.score(X_test_LR, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR_36gaatwZ3",
        "outputId": "b411ea07-9495-4ff8-abb2-3e6ba1c2947f"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9258"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evUqZRLOt2IS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}